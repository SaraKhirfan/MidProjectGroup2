# ğŸ§  AI-Powered Code Assistant with Tokenization &amp; Evaluation Pipeline

**HTU, Midterm Project, Generative AI Track ICT Upskilling Program â€” 11 Dec 2025**

Group 2: Sondos Ibrahim, Sara Khirfan, [Sadeel Alhaleeq](https://github.com/sadeelalhaleeq03) , Tasneem Alassaf

This project demonstrates an AI-powered code assistant capable of explaining, debugging, improving, and testing code using modern LLM techniques. It also includes an evaluation pipeline, tokenization experiments, and a hallucination detection framework implemented in a Google Colab notebook.

---

## ğŸ“Œ Project Overview

The Code Assistant is a multi-feature system designed to support developers by providing:

- Code explanation (3 detail levels)
- Bug detection & root cause analysis
- Code optimization suggestions (performance, readability, security)
- Automatic unit test generation
- Code translation between programming languages

Additionally, the project evaluates:

- Tokenization efficiency
- Automated vs. human evaluation metrics
- Hallucination detection & mitigation
- Prompt optimization for reliability and cost reduction

---

## ğŸ¯ Project Objectives

- Analyze tokenization and its impact on model efficiency and cost  
- Compare automated vs. human evaluations of model-generated summaries  
- Build a multi-feature code assistant optimized for clarity and control  
- Reduce hallucinations using structured prompting and context grounding  

---

## âš™ï¸ Features

### âœ… 1. Code Explanation
- Basic, medium, and high-detail explanations  
- Designed for readability and learning  

### âœ… 2. Debugging & Root Cause Analysis
- Identifies issues in user code  
- Suggests corrections and improvements  

### âœ… 3. Code Enhancement
- Improves structure, readability, efficiency, and security  
- Offers alternative implementations when needed  

### âœ… 4. Automatic Unit Test Generation
- Generates comprehensive tests with normal and edge cases  
- Covers 10â€“15 test cases per function  

### âœ… 5. Code Translation
- Converts code between languages (Python â‡† JavaScript, C++, Java, etc.)  

### âœ… 6. Token Counting & Cost Awareness
- Tracks token usage for efficiency and budget optimization  

---

## ğŸ“Š Part B: Experiments & Evaluation

### B.1 Tokenization Experiment

Tokenizers tested on the same Python sample:

| Tokenizer        | Token Count |
|------------------|-------------|
| WordPiece        | 77          |
| SentencePiece    | 84          |
| BPE              | 97          |

**Finding:** WordPiece was **26% more efficient** for Python code â€” an unexpected result.

---

### B.2 Evaluation Pipeline

- Used **ROUGE-1** and **BLEU** for automated scoring  
- Designed a **human evaluation rubric** (clarity, correctness, coherence)  
- Compared **basic vs detailed prompts**  

#### ğŸ“ˆ Automated Results

- ROUGE-1: Basic = 0.641, Detailed = 0.615  
- BLEU: Basic = 23.35, Detailed = 29.01  

> Automated metrics failed to capture the true quality difference.

#### ğŸ‘¨â€ğŸ« Human Evaluation

- Basic Prompt: **14 / 15**  
- Detailed Prompt: **15 / 15 (Perfect)**  

---

### B.3 Optimization Reflection

- Tokenizer choice affects cost (**26% difference**)  
- Detailed prompts give better results despite similar ROUGE scores  
- Sequence length requires balancing cost vs. completeness  

---

## ğŸ›‘ Part C: Hallucination Detection & Fixing

This section evaluates how LLMs hallucinate and how to eliminate the issue.

### ğŸ”¥ 1. Weak Prompt (Baseline)

- Asked about non-existent library **"FastML"**
- Model produced 1500+ words of fabricated features and comparisons  
- **Severe hallucination**

### ğŸ§Š 2. Improved Prompt

- Added rules: verify existence, avoid speculation  
- Model correctly answered:  
  > â€œFastML is not a recognized library.â€  
- Suggested real alternatives  
- **Reduced hallucination to zero**

### ğŸ›¡ï¸ 3. Context Grounding (RAG Simulation)

- Provided limited context  
- Forced model to answer **ONLY from context**  
- Output:  
  > â€œNot found in provided documentation.â€

#### ğŸ¯ Key Insight:
**Prompt structure and context grounding eliminate hallucinations far better than disclaimers.**

---

## ğŸ—ï¸ System Implementation (Colab Notebook)

The Colab notebook includes:

- Modular prompt templates  
- Tokenization toolset  
- Evaluation functions (BLEU / ROUGE)  
- Model inference logic  
- Error handling  
- Hallucination detection workflows  
- Visualization for tokenization & evaluation results  

 ---
## ğŸ Conclusion

This project demonstrates a practical, optimized, and reliable code assistant powered by modern LLMs.
Through structured prompting, evaluation analysis, and hallucination detection, the system achieves:
-âœ… High accuracy

-âœ… High clarity

-âœ… Low hallucination

-âœ… Low cost

-âœ… Developer-friendly behavior

It serves as a useful tool for software developers, students, and researchers working with code and AI models.


